{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import typing as t\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define dataset information\n",
    "IMAGE_SHAPE = (3, 224, 224)  # Shape of the input images: (channels, height, width)\n",
    "NUM_CLASSES = 100  # Number of classes in the dataset\n",
    "DATASET_SIZE = 1000  # Size of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_logging(\n",
    "    prename: str = \"log\",\n",
    "    log_level: str = \"INFO\",\n",
    "    log_path: str = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Configures the logging system to save logs at a specified level to a file with a name\n",
    "    based on a user-provided prefix and the current datetime. Optionally, logs can also be\n",
    "    output to the console.\n",
    "\n",
    "    Parameters:\n",
    "    - prename (str): Prefix for the logfile name.\n",
    "    - log_level (str): Logging level as a string ('INFO', 'DEBUG', 'ERROR', etc.).\n",
    "    - log_path (str): Directory path for the log file. If None, saves in the current directory.\n",
    "    \"\"\"\n",
    "    # Create or get a named logger\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.getLevelName(log_level.upper()))\n",
    "\n",
    "    # Clear existing handlers\n",
    "    logger.handlers = []\n",
    "\n",
    "    # Format the current date and time to append to the filename\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    if log_path:\n",
    "        os.makedirs(log_path, exist_ok=True)  # Ensure the log directory exists\n",
    "        filename = os.path.join(log_path, f\"{prename}_{current_time}.log\")\n",
    "    else:\n",
    "        filename = f\"{prename}_{current_time}.log\"\n",
    "\n",
    "    # Create file handler for logging to a file\n",
    "    file_handler = logging.FileHandler(filename)\n",
    "    file_handler.setLevel(logging.getLevelName(log_level.upper()))\n",
    "\n",
    "    # Optionally, create console handler for logging to the console\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.getLevelName(log_level.upper()))\n",
    "\n",
    "    # Create a formatter and set it for both handlers\n",
    "    formatter = logging.Formatter(\n",
    "        \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "    )\n",
    "    file_handler.setFormatter(formatter)\n",
    "    console_handler.setFormatter(formatter)\n",
    "\n",
    "    # Add handlers to the logger\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "\n",
    "    logger.info(\"Logging is configured and started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device_info(device: torch.device) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves information about the specified torch device.\n",
    "\n",
    "    Parameters:\n",
    "    - device: torch.device - The device for which information is being retrieved.\n",
    "\n",
    "    Returns:\n",
    "    - str: A formatted string containing device details.\n",
    "    \"\"\"\n",
    "    if device.type == \"cuda\":\n",
    "        info = torch.cuda.get_device_properties(device)\n",
    "        return f\"Device: {device} (Name: {info.name}, Memory: {info.total_memory / 1e9:.2f} GB)\"\n",
    "    else:\n",
    "        return f\"Device: {device} (CPU)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_size(model: nn.Module) -> str:\n",
    "    \"\"\"\n",
    "    Calculates the total number of trainable parameters in a model and estimates its size in megabytes (MB).\n",
    "\n",
    "    Parameters:\n",
    "    - model: nn.Module - The model whose parameters are being counted.\n",
    "\n",
    "    Returns:\n",
    "    - str: A formatted string stating the total number of trainable parameters and their size in MB.\n",
    "    \"\"\"\n",
    "    model_parameters = sum(\n",
    "        param.numel() for param in model.parameters() if param.requires_grad\n",
    "    )\n",
    "\n",
    "    # Assuming 32-bit floats (4 bytes per parameter)\n",
    "    bytes_per_parameter = 4\n",
    "    total_bytes = model_parameters * bytes_per_parameter\n",
    "    total_megabytes = total_bytes / (1024**2)  # Convert bytes to megabytes\n",
    "\n",
    "    return f\"Model Size: {model_parameters} parameters, {total_megabytes:.2f} MB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_batch_size(\n",
    "    model: nn.Module,\n",
    "    device: torch.device,\n",
    "    input_shape: t.Tuple[int, int, int],\n",
    "    output_shape: t.Tuple[int],\n",
    "    dataset_size: int,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    max_batch_size: int = None,\n",
    "    num_iterations: int = 5,\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Determines the optimal batch size for training based on available device memory.\n",
    "\n",
    "    Parameters:\n",
    "    - model: nn.Module - The model to be trained.\n",
    "    - device: torch.device - The device on which the model will be trained.\n",
    "    - input_shape: Tuple[int, int, int] - The shape of the input data.\n",
    "    - output_shape: Tuple[int] - The shape of the output data.\n",
    "    - dataset_size: int - The total size of the dataset.\n",
    "    - optimizer: torch.optim.Optimizer - The optimizer used for training.\n",
    "    - max_batch_size: int (optional) - The maximum allowable batch size.\n",
    "    - num_iterations: int (optional) - The number of iterations to test for memory errors.\n",
    "\n",
    "    Returns:\n",
    "    - int: The determined optimal batch size.\n",
    "    \"\"\"\n",
    "    logging.info(\"Starting batch size determination.\")\n",
    "    logging.info(get_device_info(device))\n",
    "    logging.info(get_model_size(model))\n",
    "\n",
    "    if max_batch_size is not None and max_batch_size <= 0:\n",
    "        logging.error(\"max_batch_size must be a positive integer.\")\n",
    "        raise ValueError(\"max_batch_size must be a positive integer\")\n",
    "    if dataset_size <= 0:\n",
    "        logging.error(\"dataset_size must be a positive integer.\")\n",
    "        raise ValueError(\"dataset_size must be a positive integer\")\n",
    "\n",
    "    batch_size = 2\n",
    "    while True:\n",
    "        logging.info(f\"Testing batch size: {batch_size}\")\n",
    "        if max_batch_size is not None and batch_size > max_batch_size:\n",
    "            batch_size = max_batch_size\n",
    "            logging.info(f\"Reached max_batch_size. Setting batch size to {batch_size}.\")\n",
    "            break\n",
    "        if batch_size > dataset_size:\n",
    "            batch_size = dataset_size\n",
    "            logging.info(\n",
    "                f\"Batch size exceeds dataset size. Setting batch size to {batch_size}.\"\n",
    "            )\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                for _ in range(num_iterations):\n",
    "                    inputs = torch.rand(batch_size, *input_shape, device=device)\n",
    "                    targets = torch.rand(batch_size, *output_shape, device=device)\n",
    "                    optimizer.zero_grad()\n",
    "                    with torch.enable_grad():\n",
    "                        outputs = model(inputs)\n",
    "                        loss = F.mse_loss(outputs, targets)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            logging.info(\n",
    "                f\"Batch size {batch_size} successful. Doubling batch size for next test.\"\n",
    "            )\n",
    "            batch_size *= 2\n",
    "        except RuntimeError as e:\n",
    "            if \"out of memory\" in str(e):\n",
    "                batch_size = max(2, batch_size // 2)\n",
    "                logging.warning(\n",
    "                    f\"Out of memory error with batch size {batch_size*2}. Halving to {batch_size}.\"\n",
    "                )\n",
    "                break\n",
    "            else:\n",
    "                logging.error(\"Unexpected RuntimeError.\", exc_info=True)\n",
    "                raise e\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    logging.info(f\"Final optimal batch size determined: {batch_size}\")\n",
    "    return batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(\n",
    "    batch_size: int, num_workers: int = 2\n",
    ") -> t.Tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"\n",
    "    Prepares DataLoader instances for training and testing datasets.\n",
    "\n",
    "    Parameters:\n",
    "    - batch_size: int - The batch size for data loading.\n",
    "    - num_workers: int (optional) - The number of worker processes for data loading.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[DataLoader, DataLoader]: A tuple containing the training and testing DataLoaders.\n",
    "    \"\"\"\n",
    "    train_ds = DataLoader(\n",
    "        datasets.FakeData(\n",
    "            size=DATASET_SIZE,\n",
    "            image_size=IMAGE_SHAPE,\n",
    "            num_classes=NUM_CLASSES,\n",
    "            transform=transforms.Compose([transforms.ToTensor()]),\n",
    "        ),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "    test_ds = DataLoader(\n",
    "        datasets.FakeData(\n",
    "            size=200,\n",
    "            image_size=IMAGE_SHAPE,\n",
    "            num_classes=NUM_CLASSES,\n",
    "            transform=transforms.Compose([transforms.ToTensor()]),\n",
    "        ),\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A modified ResNet model for classification.\n",
    "\n",
    "    Inherits from nn.Module and integrates a pretrained ResNet50 model with a custom output layer for classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.resnet = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.GELU(),\n",
    "            nn.Linear(in_features=1000, out_features=NUM_CLASSES),\n",
    "            nn.LogSoftmax(dim=-1),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        Parameters:\n",
    "        - inputs: torch.Tensor - The input data.\n",
    "\n",
    "        Returns:\n",
    "        - torch.Tensor: The model's output.\n",
    "        \"\"\"\n",
    "        outputs = self.resnet(inputs)\n",
    "        outputs = self.output_layer(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    train_ds: DataLoader,\n",
    "    device: torch.device,\n",
    ") -> t.Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Trains the model on the training dataset for one epoch.\n",
    "\n",
    "    Parameters:\n",
    "    - model: nn.Module - The model to be trained.\n",
    "    - optimizer: torch.optim.Optimizer - The optimizer for training.\n",
    "    - train_ds: DataLoader - The DataLoader for the training data.\n",
    "    - device: torch.device - The device on which to perform training.\n",
    "\n",
    "    Returns:\n",
    "    - Dict[str, float]: A dictionary containing the average loss and accuracy for the training epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    train_loss, correct = 0, 0\n",
    "    for _, (data, target) in enumerate(tqdm(train_ds, desc=\"Train\")):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred = output.argmax(\n",
    "            dim=1, keepdim=True\n",
    "        )  # Simplified from max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    return {\n",
    "        \"loss\": train_loss\n",
    "        / len(train_ds.dataset),  # Corrected to divide by dataset size for average\n",
    "        \"accuracy\": 100.0 * correct / len(train_ds.dataset),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(\n",
    "    model: nn.Module,\n",
    "    test_ds: DataLoader,\n",
    "    device: torch.device,\n",
    ") -> t.Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluates the model on the testing dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - model: nn.Module - The model to be evaluated.\n",
    "    - test_ds: DataLoader - The DataLoader for the testing data.\n",
    "    - device: torch.device - The device on which to perform evaluation.\n",
    "\n",
    "    Returns:\n",
    "    - Dict[str, float]: A dictionary containing the average loss and accuracy for the testing data.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_ds, desc=\"Test\"):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    return {\n",
    "        \"loss\": test_loss\n",
    "        / len(test_ds.dataset),  # Corrected to divide by dataset size for average\n",
    "        \"accuracy\": 100.0 * correct / len(test_ds.dataset),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model: nn.Module, checkpoint_path: str = None) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Loads a model's weights from a checkpoint if available, otherwise returns the provided model as is.\n",
    "\n",
    "    Parameters:\n",
    "    - model: nn.Module - The model to load the weights into.\n",
    "    - checkpoint_path: str (optional) - The path to the model checkpoint to load.\n",
    "\n",
    "    Returns:\n",
    "    - nn.Module: The model with loaded weights if a valid checkpoint is provided, otherwise the original model.\n",
    "    \"\"\"\n",
    "    if checkpoint_path and os.path.isfile(checkpoint_path):\n",
    "        # Check the file extension\n",
    "        _, file_extension = os.path.splitext(checkpoint_path)\n",
    "        if file_extension not in [\".pth\", \".pt\"]:\n",
    "            logging.warning(\n",
    "                f\"Unsupported file extension: {file_extension}. Expected .pth or .pt\"\n",
    "            )\n",
    "            return model\n",
    "\n",
    "        logging.info(f\"Loading model from checkpoint: {checkpoint_path}\")\n",
    "        model.load_state_dict(\n",
    "            torch.load(checkpoint_path, map_location=lambda storage, loc: storage)\n",
    "        )\n",
    "    else:\n",
    "        logging.info(\"No checkpoint found or provided. Using the initialized model.\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(epochs: int = 2):\n",
    "    if not torch.cuda.is_available():\n",
    "        raise RuntimeError(\"CUDA is not available.\")\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    # Prompt the user for the model checkpoint path\n",
    "    checkpoint_path = input(\n",
    "        \"Enter the model checkpoint path (leave blank if none): \"\n",
    "    ).strip()\n",
    "\n",
    "    # Instantiate the model before loading\n",
    "    model = ResNet()  # or any other model you wish to use\n",
    "    if checkpoint_path:  # Only attempt to load if a path is provided\n",
    "        model = load_model(model, checkpoint_path)\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    configure_logging(\"resnet50_training\", log_path=\"logs\")\n",
    "\n",
    "    batch_size = get_optimal_batch_size(\n",
    "        model=model,\n",
    "        device=device,\n",
    "        input_shape=IMAGE_SHAPE,\n",
    "        output_shape=(NUM_CLASSES,),\n",
    "        dataset_size=DATASET_SIZE,\n",
    "        optimizer=optimizer,\n",
    "    )\n",
    "\n",
    "    train_ds, test_ds = get_datasets(batch_size=batch_size)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "        train_result = train(\n",
    "            model=model, optimizer=optimizer, train_ds=train_ds, device=device\n",
    "        )\n",
    "        test_result = test(model=model, test_ds=test_ds, device=device)\n",
    "        print(\n",
    "            f'Train loss: {train_result[\"loss\"]:.04f}\\t'\n",
    "            f'accuracy: {train_result[\"accuracy\"]:.2f}%\\n'\n",
    "            f'Test loss: {test_result[\"loss\"]:.04f}\\t'\n",
    "            f'accuracy: {test_result[\"accuracy\"]:.2f}%'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
