{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define dataset information\n",
    "IMAGE_SHAPE = (3, 224, 224)  # Shape of the input images: (channels, height, width)\n",
    "NUM_CLASSES = 100  # Number of classes in the dataset\n",
    "DATASET_SIZE = 1000  # Size of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device_info(device: torch.device):\n",
    "    if device.type == \"cuda\":\n",
    "        info = torch.cuda.get_device_properties(device)\n",
    "        return f\"Device: {device} (Name: {info.name}, Memory: {info.total_memory / 1e9:.2f} GB)\"\n",
    "    else:\n",
    "        return f\"Device: {device} (CPU)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_size(model: nn.Module):\n",
    "    model_parameters = sum(\n",
    "        param.numel() for param in model.parameters() if param.requires_grad\n",
    "    )\n",
    "    return f\"Model Size: {model_parameters} parameters\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_batch_size(\n",
    "    model: nn.Module,\n",
    "    device: torch.device,\n",
    "    input_shape: t.Tuple[int, int, int],\n",
    "    output_shape: t.Tuple[int],\n",
    "    dataset_size: int,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    max_batch_size: int = None,\n",
    "    num_iterations: int = 5,\n",
    ") -> int:\n",
    "    logging.info(\"Starting batch size determination.\")\n",
    "    logging.info(get_device_info(device))\n",
    "    logging.info(get_model_size(model))\n",
    "\n",
    "    if max_batch_size is not None and max_batch_size <= 0:\n",
    "        logging.error(\"max_batch_size must be a positive integer.\")\n",
    "        raise ValueError(\"max_batch_size must be a positive integer\")\n",
    "    if dataset_size <= 0:\n",
    "        logging.error(\"dataset_size must be a positive integer.\")\n",
    "        raise ValueError(\"dataset_size must be a positive integer\")\n",
    "\n",
    "    batch_size = 2\n",
    "    while True:\n",
    "        logging.info(f\"Testing batch size: {batch_size}\")\n",
    "        if max_batch_size is not None and batch_size > max_batch_size:\n",
    "            batch_size = max_batch_size\n",
    "            logging.info(f\"Reached max_batch_size. Setting batch size to {batch_size}.\")\n",
    "            break\n",
    "        if batch_size > dataset_size:\n",
    "            batch_size = dataset_size\n",
    "            logging.info(\n",
    "                f\"Batch size exceeds dataset size. Setting batch size to {batch_size}.\"\n",
    "            )\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                for _ in range(num_iterations):\n",
    "                    inputs = torch.rand(batch_size, *input_shape, device=device)\n",
    "                    targets = torch.rand(batch_size, *output_shape, device=device)\n",
    "                    optimizer.zero_grad()\n",
    "                    with torch.enable_grad():\n",
    "                        outputs = model(inputs)\n",
    "                        loss = F.mse_loss(outputs, targets)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            logging.info(\n",
    "                f\"Batch size {batch_size} successful. Doubling batch size for next test.\"\n",
    "            )\n",
    "            batch_size *= 2\n",
    "        except RuntimeError as e:\n",
    "            if \"out of memory\" in str(e):\n",
    "                batch_size = max(2, batch_size // 2)\n",
    "                logging.warning(\n",
    "                    f\"Out of memory error with batch size {batch_size*2}. Halving to {batch_size}.\"\n",
    "                )\n",
    "                break\n",
    "            else:\n",
    "                logging.error(\"Unexpected RuntimeError.\", exc_info=True)\n",
    "                raise e\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    logging.info(f\"Final optimal batch size determined: {batch_size}\")\n",
    "    return batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(batch_size: int, num_workers: int = 2):\n",
    "    train_ds = DataLoader(\n",
    "        datasets.FakeData(\n",
    "            size=DATASET_SIZE,\n",
    "            image_size=IMAGE_SHAPE,\n",
    "            num_classes=NUM_CLASSES,\n",
    "            transform=transforms.Compose([transforms.ToTensor()]),\n",
    "        ),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "    test_ds = DataLoader(\n",
    "        datasets.FakeData(\n",
    "            size=200,\n",
    "            image_size=IMAGE_SHAPE,\n",
    "            num_classes=NUM_CLASSES,\n",
    "            transform=transforms.Compose([transforms.ToTensor()]),\n",
    "        ),\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.resnet = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.GELU(),\n",
    "            nn.Linear(\n",
    "                in_features=1000, out_features=NUM_CLASSES\n",
    "            ),  # Assuming the feature size before the classifier is 1000\n",
    "            nn.LogSoftmax(dim=-1),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor):\n",
    "        outputs = self.resnet(inputs)\n",
    "        outputs = self.output_layer(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim,\n",
    "    train_ds: DataLoader,\n",
    "    device: torch.device,\n",
    "):\n",
    "    model.train()\n",
    "    train_loss, correct = 0, 0\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_ds, desc=\"Train\")):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    return {\n",
    "        \"loss\": train_loss / len(train_ds),\n",
    "        \"accuracy\": 100.0 * correct / len(train_ds.dataset),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model: nn.Module, test_ds: DataLoader, device: torch.device):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss, correct = 0, 0\n",
    "        for data, target in tqdm(test_ds, desc=\"Test\"):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target).item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    return {\n",
    "        \"loss\": test_loss / len(test_ds),\n",
    "        \"accuracy\": 100.0 * correct / len(test_ds.dataset),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(epochs: int = 2):\n",
    "    if not torch.cuda.is_available():\n",
    "        raise RuntimeError(\"CUDA is not available.\")\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    # Instantiate the model first to pass to get_optimal_batch_size\n",
    "    model = ResNet().to(device)\n",
    "\n",
    "    # Updated to reflect correct argument names and usage\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    batch_size = get_optimal_batch_size(\n",
    "        model=model,\n",
    "        device=device,\n",
    "        input_shape=IMAGE_SHAPE,\n",
    "        output_shape=(NUM_CLASSES,),\n",
    "        dataset_size=DATASET_SIZE,\n",
    "        optimizer=optimizer,\n",
    "    )\n",
    "\n",
    "    train_ds, test_ds = get_datasets(batch_size=batch_size)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "        train_result = train(\n",
    "            model=model, optimizer=optimizer, train_ds=train_ds, device=device\n",
    "        )\n",
    "        test_result = test(model=model, test_ds=test_ds, device=device)\n",
    "        print(\n",
    "            f'Train loss: {train_result[\"loss\"]:.04f}\\t'\n",
    "            f'accuracy: {train_result[\"accuracy\"]:.2f}%\\n'\n",
    "            f'Test loss: {test_result[\"loss\"]:.04f}\\t'\n",
    "            f'accuracy: {test_result[\"accuracy\"]}%'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
